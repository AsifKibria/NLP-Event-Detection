{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f27e471",
   "metadata": {},
   "source": [
    "\n",
    "## NLP Event Detection Assignment\n",
    "I've used the following methods:\n",
    "- Get 5WH Questions answers by GiveMe5W1H\n",
    "- Counting events on the base of Protagonist (Who), Location (Where) and Object chages (What) usinng sentence tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f78770cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "#User_agent is required, DEFAULT user_agent is blocked.\n",
    "geopy.geocoders.options.default_user_agent = \"nlpEventDetection\" \n",
    "\n",
    "from Giveme5W1H.extractor.document import Document\n",
    "from Giveme5W1H.extractor.extractor import MasterExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e7f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    OK = '\\033[92m' \n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    RESET = '\\033[0m'\n",
    "def getWh(data):\n",
    "    whQuestions = [\"who\", \"when\", \"what\", \"where\", \"why\", \"how\"]\n",
    "    extractor = MasterExtractor()\n",
    "    doc = Document.from_text(data)\n",
    "    doc = extractor.parse(doc)    \n",
    "    for wh in whQuestions:\n",
    "        try:\n",
    "            event = doc.get_top_answer(wh).get_parts_as_text()\n",
    "            print(bcolors.OK + wh + bcolors.RESET + \": \\t  \" + event)\n",
    "        except IndexError:\n",
    "            print(bcolors.FAIL + wh + bcolors.RESET + \": \\t \" + bcolors.WARNING + \" There is no \"  + bcolors.RESET + bcolors.FAIL + wh + bcolors.RESET  +   bcolors.WARNING + \" event detected in this chapter.\" + bcolors.RESET)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff9943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/01villa.txt', 'r') as file:\n",
    "    ch1 = file.read().replace('\\n', '')\n",
    "#print(ch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df8692e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mwho\u001b[0m: \t  Pippi\n",
      "\u001b[91mwhen\u001b[0m: \t \u001b[93m There is no \u001b[0m\u001b[91mwhen\u001b[0m\u001b[93m event detected in this chapter.\u001b[0m\n",
      "\u001b[92mwhat\u001b[0m: \t  was nine years\n",
      "\u001b[92mwhere\u001b[0m: \t  Egypt\n",
      "\u001b[92mwhy\u001b[0m: \t  because there was no one to tell her to go to bed just when she was having the most fun , and no one who could make her take cod liver oil when she much preferred caramel candy.Once upon a time Pippi had had a father of whom she was extremely fond .\n",
      "\u001b[92mhow\u001b[0m: \t  a tiny little town was an old overgrown garden ,\n"
     ]
    }
   ],
   "source": [
    "getWh(ch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f7ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/02thing.txt', 'r') as file:\n",
    "    ch2 = file.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "390a7546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mwho\u001b[0m: \t  Annika.That morning Pippi\n",
      "\u001b[91mwhen\u001b[0m: \t \u001b[93m There is no \u001b[0m\u001b[91mwhen\u001b[0m\u001b[93m event detect in this chapter.\u001b[0m\n",
      "\u001b[92mwhat\u001b[0m: \t  was busy making pepparkakor\n",
      "\u001b[92mwhere\u001b[0m: \t  Pippi\n",
      "\u001b[92mwhy\u001b[0m: \t  Because , \" said Pippi to her little monkey , \" what earthly use is a baking board when one plans to make at least five hundred cookies ?\n",
      "\u001b[92mhow\u001b[0m: \t  her little monkey , \" what earthly use is a\n"
     ]
    }
   ],
   "source": [
    "getWh(ch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17e64db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/03police.txt', 'r') as file:\n",
    "    ch3 = file.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "862207b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mwho\u001b[0m: \t  Pippi\n",
      "\u001b[91mwhen\u001b[0m: \t \u001b[93m There is no \u001b[0m\u001b[91mwhen\u001b[0m\u001b[93m event detect in this chapter.\u001b[0m\n",
      "\u001b[92mwhat\u001b[0m: \t  could reach.Just at that moment two police officers\n",
      "\u001b[92mwhere\u001b[0m: \t  Portugal\n",
      "\u001b[92mwhy\u001b[0m: \t  because she wanted to have a little fun with the policemen , but they did n't think it was funny at all.They said she should n't be such a smarty .\n",
      "\u001b[92mhow\u001b[0m: \t  It soon became known throughout the little town that a\n"
     ]
    }
   ],
   "source": [
    "getWh(ch3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752f272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "chSents = sent_tokenize(ch3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d11159f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Portugal you grow up\n",
      "2 Lisbon she added\n",
      "Total Where Events: 8\n",
      "Total Who Events: 2\n",
      "Total What Events: 2\n"
     ]
    }
   ],
   "source": [
    "whoEventsNumber, whatEventsNumber,whereEventsNumber = 0, 0, 0,0\n",
    "for sents in chSents:\n",
    "    try:\n",
    "        extractor = MasterExtractor()\n",
    "        doc = Document.from_text(sents)\n",
    "        doc = extractor.parse(doc)\n",
    "        try:\n",
    "            whereEvents = doc.get_top_answer(\"where\").get_parts_as_text()\n",
    "            whereEventsNumber += 1\n",
    "        except IndexError:\n",
    "            whereEvents = \"Not Found\"\n",
    "            continue\n",
    "        try:\n",
    "            whoEvents = doc.get_top_answer(\"who\").get_parts_as_text()\n",
    "            whoEventsNumber += 1\n",
    "        except IndexError:\n",
    "            whoEvents = \"Not Found\"\n",
    "            continue\n",
    "        try:\n",
    "            whatEvents = doc.get_top_answer(\"what\").get_parts_as_text()\n",
    "            whatEventsNumber += 1\n",
    "        except IndexError:\n",
    "            whatEvents = \"Not Found\"\n",
    "            continue\n",
    "    except IndexError:\n",
    "        continue    \n",
    "print(\"Total Where Events:\", whereEventsNumber)\n",
    "print(\"Total Who Events:\", whoEventsNumber)\n",
    "print(\"Total What Events:\", whatEventsNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39236056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e5e1ae2c3041ee61294d176785377fef35c3ff5eca4ba9267d54be681a7d9c9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
